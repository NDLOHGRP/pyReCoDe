{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29c03da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "sys.path.insert(0, '/mnt/cbis/home/amandakau/pyReCoDe')\n",
    "from pyrecode.recode_reader import ReCoDeReader\n",
    "\n",
    "import multiprocessing\n",
    "import queue\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b6c0a",
   "metadata": {},
   "source": [
    "When reading ReCoDe part files, first fetch data in batches using __ReaderNode__. Downstream applications may read data provided by ReaderNode instead of by ReCoDeReader. One application to aggregate all available part files is achieved in the __ReCoDeViewer__ and __ReCoDeViewer_MP__ classes. The main difference between these two classes is the former doesn't support multiprocessing while the latter does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c3de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReaderNode:\n",
    "    def __init__(self, file_name, file_id):\n",
    "        self._file_name = file_name\n",
    "        self._file_id = file_id\n",
    "        self._is_read = False\n",
    "        \n",
    "        self._reader = ReCoDeReader(file_name, is_intermediate=True)\n",
    "        self._reader.open(print_header=False)\n",
    "        header = self._reader.get_header().as_dict()\n",
    "        \n",
    "        self._shape = (header['nx'], header['ny'])\n",
    "        self._curr_position = self._reader._current_frame_index\n",
    "        \n",
    "    def get_next_batch(self, batch_size=60):\n",
    "        count = 0\n",
    "        batch_data = []\n",
    "        \n",
    "        while count < batch_size and self._is_read == False:\n",
    "            frame_data = self._reader.get_next_frame()\n",
    "            if frame_data is None:\n",
    "                self.is_read = True\n",
    "                break\n",
    "            else:\n",
    "                frame_id = list(frame_data.keys())[0]\n",
    "                batch_data.append(frame_data[frame_id]['data'])\n",
    "                count += 1\n",
    "            del(frame_data)\n",
    "        \n",
    "        self._curr_position = self._reader._current_frame_index\n",
    "        return (self._file_id, batch_data)\n",
    "    \n",
    "    def get_shape(self):\n",
    "        return self._shape\n",
    "    \n",
    "    def get_status(self):\n",
    "        read_status = 'read' if self._is_read else 'still being read'\n",
    "        pos_status = '' if self._is_read else f' (Current position at {self._curr_position})'\n",
    "        print(f'{self._file_name} corresponding to part file #{self._file_id} is {read_status}{pos_status}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998f7807",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19f0c04f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ReCoDeViewer:\n",
    "    def __init__(self, folder_path, file_name, num_parts, batch_size=60):\n",
    "        self._folder_path = folder_path\n",
    "        self._file_name = file_name\n",
    "        self._num_parts = num_parts\n",
    "        self._batch_size = batch_size\n",
    "        \n",
    "        #Create ReaderNodes for each part file to fetch batch data\n",
    "        self._part_files = {}\n",
    "        for index in range(self._num_parts):\n",
    "            part_file_name = os.path.join(self._folder_path, self._file_name + '_part' + '{0:03d}'.format(index))\n",
    "            self._part_files[index] = ReaderNode(part_file_name, index)\n",
    "    \n",
    "    def get_info(self):\n",
    "        print(f'Reading from {self._num_parts} part files:')\n",
    "        for index in self._part_files.keys():\n",
    "            self._part_files[index].get_status()\n",
    "    \n",
    "    def sum_frames(self, part_file_id, batch_data, final_result):\n",
    "        summed_frame = coo_matrix(self._part_files[0]._shape)\n",
    "        for frame in batch_data:\n",
    "            summed_frame += frame # Maintains the COO matrix\n",
    "                \n",
    "        #Save result\n",
    "        if part_file_id not in final_result:\n",
    "            final_result[part_file_id] = summed_frame\n",
    "        else:\n",
    "            final_result[part_file_id] = np.add(final_result[part_file_id], summed_frame)\n",
    "        \n",
    "        batch_data.clear()\n",
    "        return summed_frame\n",
    "    \n",
    "    def combine_part_files(self, final_result):\n",
    "        shape = self._part_files[0]._shape\n",
    "        summed_frame = np.zeros(shape)\n",
    "        \n",
    "        for index in range(self._num_parts):\n",
    "            if index not in final_result:\n",
    "                break\n",
    "                \n",
    "            #If the image in the part file has different dimensions, skip this part file\n",
    "            elif np.shape(final_result[index]) != shape:\n",
    "                print(f'Part file #{index} does not have the same dimensions - cannot be aggregated.')\n",
    "                break\n",
    "\n",
    "            summed_frame = np.add(summed_frame, final_result[index].toarray())\n",
    "\n",
    "        return summed_frame\n",
    "    \n",
    "    def plot_frame(self, frame, part_file_id, num_frames):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(20,10))\n",
    "        im = ax.imshow(frame, vmax=np.amax(frame))\n",
    "        if (part_file_id == -1) and (num_frames == 0):\n",
    "            ax.set(title = 'Showing aggregate image sum of all part files combined')\n",
    "        else:\n",
    "            ax.set(title = f'Showing sum of {num_frames} frames from part file #{part_file_id}')\n",
    "        fig.colorbar(im)\n",
    "        plt.show()\n",
    "\n",
    "    def start(self, plot_result=True, plot_intermediate=False, interval=50):\n",
    "        \"\"\"Returns array containing the aggregate sum of all part files.\n",
    "        \n",
    "        Parameters:\n",
    "        plot_result: True if want the final aggregate sum of all part files to be plotted\n",
    "        plot_intermediate: True if want data to be plotted every n-th iteration, where n is specified in 'interval'\n",
    "        interval: n, where data is aggregated and plotted every n-th iteration\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        is_completed = False\n",
    "        iteration = 0\n",
    "        \n",
    "        job_queue = queue.Queue()\n",
    "        final_result = {}\n",
    "        \n",
    "        while not is_completed:\n",
    "            num_files_done = 0\n",
    "            \n",
    "            for index in range(self._num_parts):\n",
    "                if (self._part_files[index]._is_read == False): #There's still a job to do\n",
    "                    data = self._part_files[index].get_next_batch()\n",
    "                    job_queue.put(data)  \n",
    "                else:\n",
    "                    num_files_done += 1\n",
    "                    if (num_files_done == self._num_parts):\n",
    "                        is_completed = True\n",
    "            \n",
    "            #Do jobs in queue\n",
    "            while not job_queue.empty():\n",
    "                summed_frame = self.sum_frames(*job_queue.get(), final_result)\n",
    "            \n",
    "            iteration += 1\n",
    "            if (iteration % interval == 0):\n",
    "                print(f\"Time elapsed (Iteration #{iteration}): {time.time()-start} seconds\")\n",
    "                if plot_intermediate:\n",
    "                    agg = self.combine_part_files(final_result)\n",
    "                    self.plot_frame(agg, -1, 0)\n",
    "            \n",
    "        #Compute and plot aggregate image sum of all part files\n",
    "        print(\"Getting aggregate...\")\n",
    "        agg_frame = self.combine_part_files(final_result)\n",
    "        if plot_result:\n",
    "            self.plot_frame(agg_frame, -1, 0)\n",
    "        print(f\"Total time elapsed: {time.time()-start} seconds\")\n",
    "            \n",
    "        return agg_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32962ff6",
   "metadata": {},
   "source": [
    "ReCoDeViewer can be initialised and started by calling the method as shown below. Only the final result will be returned in the form of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e29c40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_data_folder = '/scratch/loh/abhik/2Sep2020/captures/'\n",
    "_tag = 'streampix_2k_60fps_run_4'\n",
    "_num_part_files = 10\n",
    "\n",
    "viewer = ReCoDeViewer(_data_folder, _tag + '.rc1', _num_part_files)\n",
    "final_result = viewer.start(interval=1, plot_intermediate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a09d1cd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67dde4f",
   "metadata": {},
   "source": [
    "If a large amount of data needs to be processed, it is recommended to use multiprocessing for faster results. __ReCoDeViewer_MP__ is based on __ReCoDeViewer__ but adapted to support multiprocessing. It can be initialised and started in the same way as ReCoDeViewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b139b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReCoDeViewer_MP(ReCoDeViewer):\n",
    "    def __init__(self, folder_path, file_name, num_parts, batch_size=60):\n",
    "        super().__init__(folder_path, file_name, num_parts, batch_size)\n",
    "        \n",
    "    def start(self, plot_result=True, num_threads=5, plot_intermediate=False, interval=50):\n",
    "        \"\"\"Returns array containing the aggregate sum of all part files.\n",
    "        \n",
    "        Parameters:\n",
    "        plot_result: True if want the final aggregate sum of all part files to be plotted\n",
    "        num_threads: Number of processes available for multiprocessing\n",
    "        plot_intermediate: True if want data to be plotted every n-th iteration, where n is specified in 'interval'\n",
    "        interval: n, where data is aggregated and plotted every n-th iteration\n",
    "        \"\"\"\n",
    "        \n",
    "        start = time.time()\n",
    "        is_completed = False\n",
    "        iteration = 0\n",
    "        \n",
    "        job_queue = multiprocessing.Queue()\n",
    "        manager = multiprocessing.Manager()\n",
    "        final_result = manager.dict()\n",
    "        processes = []\n",
    "        \n",
    "        while not is_completed:\n",
    "            num_files_done = 0\n",
    "            \n",
    "            for index in range(self._num_parts):\n",
    "                if (self._part_files[index]._is_read == False):\n",
    "                    data = self._part_files[index].get_next_batch()\n",
    "                    job_queue.put(data)\n",
    "                    \n",
    "                else:\n",
    "                    num_files_done += 1\n",
    "                    if (num_files_done == self._num_parts):\n",
    "                        is_completed = True\n",
    "                        job_queue.close()\n",
    "                        job_queue.join_thread()\n",
    "\n",
    "            while not job_queue.empty():\n",
    "                for i in range(num_threads):\n",
    "                    if job_queue.empty():\n",
    "                        break\n",
    "\n",
    "                    p = multiprocessing.Process(target=ReCoDeViewer.sum_frames, args=(self, *job_queue.get(), final_result))\n",
    "                    processes.append(p)\n",
    "                    p.start()\n",
    "\n",
    "                for p in processes:\n",
    "                    p.join()\n",
    "                    p.terminate()\n",
    "                \n",
    "                processes.clear()\n",
    "            \n",
    "            iteration += 1\n",
    "            if (iteration % interval == 0):\n",
    "                print(f\"Time elapsed (Iteration #{iteration}): {time.time()-start} seconds\")\n",
    "                if plot_intermediate:\n",
    "                    agg = self.combine_part_files(final_result)\n",
    "                    self.plot_frame(agg, -1, 0) \n",
    "            \n",
    "        #Compute and plot aggregate image sum of all part files\n",
    "        print(\"Getting aggregate...\")\n",
    "        agg_frame = self.combine_part_files(final_result)\n",
    "        if plot_result:\n",
    "            self.plot_frame(agg_frame, -1, 0)\n",
    "        print(f\"Total time elapsed: {time.time()-start} seconds\")\n",
    "            \n",
    "        return agg_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4028687",
   "metadata": {},
   "outputs": [],
   "source": [
    "_data_folder = '/scratch/loh/abhik/2Sep2020/captures/'\n",
    "_tag = 'streampix_2k_60fps_run_4'\n",
    "_num_part_files = 10\n",
    "\n",
    "viewer_MP = ReCoDeViewer_MP(_data_folder, _tag + '.rc1', _num_part_files)\n",
    "final_result_MP = viewer_MP.start(interval=1, plot_intermediate=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
